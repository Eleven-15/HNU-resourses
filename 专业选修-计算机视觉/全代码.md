# 全代码


## imgclip.py

**功能：把识别的物体的图像截取出来，但是多截取一点，前移一帧和后移一帧。一共三张图片，使训练素材更加丰富**

 ```python
> import cv2
> import json
>
> # 使用给出的json文件提取出识别的物体的图片，左移和右移一帧，所以一共3张图片，使训练素材丰富
> BASIC_PATH = 'E:/CVtask/test_clips/'
> SAVE_PATH = 'E:/CVtask/test_clips_images/'
> path = 'E:/CVtask/data_test.json'
> # index = 0
> # fw1 = open("alltypes.txt", "w")
> mydict = {}
> # 打开json文件读取到data
> with open(path, 'r') as f:
>     data = json.load(f)
> # 提取json中clips项
> clips = data['clips']
> # 接下来就是提取每一个clip，然后根据uid找到对应的视频然后截取图片
> for clip in clips:
>     annotations = clip['annotations']
>     clip_uid = clip['clip_uid']
>     cap = cv2.VideoCapture(BASIC_PATH + clip_uid + '.mp4')
>     for annotation in annotations:
>         visual_crop = annotation['visual_crop']
>         obj_title = str(annotation['object_title'])
>         for i in range(-1, 2):
>             cap.set(cv2.CAP_PROP_POS_FRAMES, visual_crop['frame_number'] * 6 + i)
>             ret, img = cap.read()
>             if mydict.get(obj_title) is None:
>                 mydict[obj_title] = 1
>                 cv2.imwrite(SAVE_PATH + obj_title + '_' + str(mydict[obj_title]) + '.jpg', img)
>             else:
>                 # fw1.write(str(index) + " " + annotation['object_title'])
>                 # fw1.write('\n')
>                 # index = index + 1
>                 # myset.add(obj_title)
>                 mydict[obj_title] += 1
>                 cv2.imwrite(SAVE_PATH + obj_title + '_' + str(mydict[obj_title]) + '.jpg', img)
>
> ```


## gettypes.py

**功能：获取所有物品的类别**

 ```python
> import cv2
> import json
>
> BASIC_PATH = 'E:/CVtask/test_clips/'
> SAVE_PATH = 'E:/CVtask/test_clips_images/'
> path = 'E:/CVtask/data_test.json'
> # index = 0
> fw1 = open("alltypes.txt", "w")
> myset = set()
> with open(path, 'r') as f:
>     data = json.load(f)
> # 提取每个clip
> clips = data['clips']
> for clip in clips:
>     annotations = clip['annotations']
>     clip_uid = clip['clip_uid']
>     # cap = cv2.VideoCapture(BASIC_PATH + clip_uid + '.mp4')
> 	# 提取每个annotation的obj_title
>     for annotation in annotations:
>         # visual_crop = annotation['visual_crop']
>         # cap.set(cv2.CAP_PROP_POS_FRAMES, visual_crop['frame_number'] * 6)
>         # ret, img = cap.read()
>         obj_title = str(annotation['object_title'])
> 		# 没有出现过这个物品则加入
>         if obj_title not in myset:
>             myset.add(obj_title)
>             fw1.write(obj_title)
>             fw1.write('\n')
>         else:
>             continue
> ```

‍

## yolotxttransfer.py

**功能：把 json 中的物品识别方框的位置大小读取出来，这里偷懒因为一帧的差别不会让方框变化太多所以 3 张图片使用的一个方框数据，然后转换成 yolov8 的标注数据，txt 格式，(具体格式可以网上搜索自行了解)**

[yolov8 格式](https://blog.csdn.net/u011775793/article/details/134918087)

 ```python
> import cv2
> import json
>
> BASIC_PATH = 'E:/CVtask/test_clips/'
> SAVE_PATH = 'E:/CVtask/test_clips_images/'
> TXT_PATH = 'E:/CVtask/test_clips_yolotxt/'
> path = 'E:/CVtask/data_test.json'
> # index = 0
> mydict = {}
> types = {}
> with open('E:/CVtask/classes_test.txt') as fr:
>     contents = fr.read()
> lines = contents.split("\n")
> index = 0
> for line in lines:
>     types[line] = index
>     index += 1
> print(types)
> with open(path, 'r') as f:
>     data = json.load(f)
> clips = data['clips']
> for clip in clips:
>     annotations = clip['annotations']
>     clip_uid = clip['clip_uid']
>     for annotation in annotations:
>         visual_crop = annotation['visual_crop']
>         obj_title = str(annotation['object_title'])
> 		# 根据visual_crop里面给出的数据，转换成yolo需要的标注集
>         yolo_x, yolo_y, yolo_w, yolo_h = float(
>             (visual_crop['x'] + visual_crop['width'] / 2) / visual_crop['original_width']), float(
>             (visual_crop['y'] + visual_crop['height'] / 2) / visual_crop['original_height']), float(
>             visual_crop['width'] / visual_crop['original_width']), float(
>             visual_crop['height'] / visual_crop['original_height'])
> 		# 与截取图片的时候的命名保持一致，这样就非常方便，因为yolo是要图片和标注名字一样的
>         for i in range(-1, 2):
>             if mydict.get(obj_title) is None:
>                 mydict[obj_title] = 1
>                 with open(TXT_PATH + obj_title + '_' + str(mydict[obj_title]) + '.txt', 'a') as fw:
>                     fw.write(
>                         str(types[obj_title]) + ' ' + str(yolo_x) + ' ' + str(yolo_y) + ' ' + str(yolo_w) + ' ' + str(
>                             yolo_h))
>             else:
>                 mydict[obj_title] += 1
>                 with open(TXT_PATH + obj_title + '_' + str(mydict[obj_title]) + '.txt', 'a') as fw:
>                     fw.write(
>                         str(types[obj_title]) + ' ' + str(yolo_x) + ' ' + str(yolo_y) + ' ' + str(yolo_w) + ' ' + str(
>                             yolo_h))
> ```

‍

## txt2json.py

**功能：把预测标注文件转换成我们在 json 中要填的数据，同时不仅有 txt 格式的结果，还有视频结果可以看到预测的效果。**

 ```python
> import os
> import json
>
> WIDTH = 1920
> HEIGHT = 1080
>
> path = 'D:/code/pyproject/opencvlearning/ultralytics-main/runs/detect/predict3/labels'
> files = os.listdir(path)
> files.sort(key=lambda x: int(x.split(".")[0].split("_")[1]))
> with open('D:/code/pyproject/opencvlearning/Resources/data_test.json') as f:
>     data = json.load(f)
>
> clips = data['clips']
> clips_uid = {}
> temp = 0
> for clip in clips:
>     clips_uid[clip['clip_uid']] = temp
>     temp += 1
> # print(clips_uid)
> types = {}
> with open('E:/CVtask/classes_test.txt') as fr:
>     contents = fr.read()
> lines = contents.split("\n")
> index = 0
> frames = []
> for line in lines:
>     types[index] = line
>     index += 1
> for file in files:
>     # print(file)
>     f = open(path + '/' + file, 'r', encoding='utf-8')
>     first_line = f.readline().rstrip()
>     yolo_data = first_line.split()
>     # print(yolo_data)
>     uid = file.split('_')[0]
>     frame = int(file.split('_')[1].split('.')[0])
>     clip_index = clips_uid[uid]
>     clip = clips[clip_index]
>     obj_title = types[int(yolo_data[0])]
>     # print(obj_title)
>     annotations = clip['annotations']
>     anno_index = 0
>     for annotation in annotations:
>         if annotation['object_title'] == obj_title:
>             break
>         else:
>             anno_index += 1
>     anno = annotations[anno_index]
>     lt_track = anno['lt_track']
>     new_dict = {}
>     new_dict['frame_number'] = frame // 6
>     new_dict['x'] = round(float(WIDTH) * float(yolo_data[1]) - 0.5 * float(WIDTH) * float(yolo_data[3]), 2)
>     new_dict['y'] = round(float(HEIGHT) * float(yolo_data[2]) - 0.5 * float(HEIGHT) * float(yolo_data[4]), 2)
>     new_dict['width'] = round(float(WIDTH) * float(yolo_data[3]), 2)
>     new_dict['height'] = round(float(HEIGHT) * float(yolo_data[4]), 2)
>     new_dict['interpolated'] = False
>     new_dict['exported_clip_frame_number'] = frame
>     lt_track.append(new_dict)
>
> # clips = data['clips']
> # for clip in clips:
> #     annotations = clip['annotations']
> #     for annotation in annotations:
> #         new_track = {}
> #         annotation['lt_track'] = []
>
> with open('D:/code/pyproject/opencvlearning/Resources/data_test.json', 'w') as newjsf:
>     json.dump(data, newjsf)
> ```

‍

## split_train_val.py

**功能：根据权重分割素材，一些作训练用的素材一些是验证，还有一些测试，运行文件之后会在imageSets文件夹下将数据集划分为训练集train.txt、验证集val.txt、测试集test.txt，里面存放的就是用于训练、验证、测试的图片名称**

```python
> import os
> import random
>
> # 根据权重分割素材，一些作训练用的素材一些是验证，还有一些测试，初始模型选择的是yolov8n.pt
> # 这个代码是网上找来的然后自己修改过，大致就是这个意思
> trainval_percent = 0.95
> train_percent = 0.95
> xmlfilepath = 'data/Annotations'
> txtsavepath = 'data/ImageSets'
> total_xml = os.listdir(xmlfilepath)
>
> num = len(total_xml)
> list = range(num)
> tv = int(num * trainval_percent)
> tr = int(tv * train_percent)
> trainval = random.sample(list, tv)
> train = random.sample(trainval, tr)
>
> ftrainval = open('data/ImageSets/trainval.txt', 'w')
> ftest = open('data/ImageSets/test.txt', 'w')
> ftrain = open('data/ImageSets/train.txt', 'w')
> fval = open('data/ImageSets/val.txt', 'w')
>
> for i in list:
>     name = total_xml[i][:-4] + '\n'
>     if i in trainval:
>         ftrainval.write(name)
>         if i in train:
>             ftrain.write(name)
>         else:
>             fval.write(name)
>     else:
>         ftest.write(name)
>
> ftrainval.close()
> ftrain.close()
> fval.close()
> ftest.close()
> ```

‍

## labeltransfer.py

**功能：因为我们的标注文件已经是yolov8的格式了，所以这个代码经过我的修改只有data文件夹下得到三个包含数据集路径的txt文件，`train.txt，test.txt，val.txt` ​​这3个txt文件为划分后图像所在位置的绝对路径**

```python
> import os
> from os import getcwd
>
> sets = ['train', 'val', 'test']
> abs_path = os.getcwd()
> print(abs_path)
>
> wd = getcwd()
> for image_set in sets:
>     if not os.path.exists('data/labels/'):
>         os.makedirs('data/labels/')
>     image_ids = open('data/ImageSets/%s.txt' % (image_set)).read().strip().split('\n')
>     list_file = open('data/%s.txt' % (image_set), 'w')
>     for image_id in image_ids:
>         list_file.write(abs_path + '/data/images/%s.jpg\n' % (image_id))
>     list_file.close()
> ```

‍
